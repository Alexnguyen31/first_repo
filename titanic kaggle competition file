{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"isSourceIdPinned":false,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)import os)\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ntrain = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\nprint(train.head())\n\n\ndef get_title(name):\n    return name.split(',')[1].split('.')[0].strip()\n\nfor df in [train, test]:\n    df['Title'] = df['Name'].apply(get_title)\n\n# Group rare titles\nfor df in [train, test]:\n    df['Title'] = df['Title'].replace(\n        ['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],\n        'Rare'\n    )\n    df['Title'] = df['Title'].replace({'Mlle':'Miss','Ms':'Miss','Mme':'Mrs'})\n\n\n# We Check missing values in train dataset:\ntrain.isnull().sum()\n\n\n# We Fill missing Age with median:\nfor title in train['Title'].unique():\n    median_age = train[train['Title'] == title]['Age'].median()\n    train.loc[(train['Age'].isnull()) & (train['Title'] == title), 'Age'] = median_age\n    test.loc[(test['Age'].isnull()) & (test['Title'] == title), 'Age'] = median_age\n\n\n\n# We Fill missing Embarked with most common value:\ntrain['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)\ntest['Embarked'].fillna(test['Embarked'].mode()[0], inplace=True)\n\ntrain.isnull().sum()\n\n\n# Create FamilySize = SibSp + Parch + 1 (self):\ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1\nfor df in [train, test]:\n    df['IsAlone'] = 0\n    df.loc[df['FamilySize'] == 1, 'IsAlone'] = 1\n\n\n\n# We  Check the first 5 rows:\ntrain[['SibSp','Parch','FamilySize']].head()\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-09T18:03:39.396548Z","iopub.execute_input":"2026-02-09T18:03:39.397368Z","iopub.status.idle":"2026-02-09T18:03:39.518505Z","shell.execute_reply.started":"2026-02-09T18:03:39.397331Z","shell.execute_reply":"2026-02-09T18:03:39.516988Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/3631390535.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)\n/tmp/ipykernel_55/3631390535.py:48: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test['Embarked'].fillna(test['Embarked'].mode()[0], inplace=True)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   SibSp  Parch  FamilySize\n0      1      0           2\n1      1      0           2\n2      0      0           1\n3      1      0           2\n4      0      0           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>FamilySize</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nimport pandas as pd\n\n\ntrain['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\ntest['Embarked'] = test['Embarked'].fillna(test['Embarked'].mode()[0])\n\n# we Encode categorical columns:\nle_sex = LabelEncoder()\ntrain['Sex'] = le_sex.fit_transform(train['Sex'])\ntest['Sex'] = le_sex.transform(test['Sex'])\n\nle_emb = LabelEncoder()\ntrain['Embarked'] = le_emb.fit_transform(train['Embarked'])\ntest['Embarked'] = le_emb.transform(test['Embarked'])\nle_title = LabelEncoder()\ntrain['Title'] = le_title.fit_transform(train['Title'])\ntest['Title'] = le_title.transform(test['Title'])\n\n#  we Create FamilySize feature:\ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n\n# the we Select features:\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'FamilySize', 'IsAlone', 'Title']\n\nX = train[features]\ny = train['Survived']\nX_test = test[features]\n\n# Train Random Forest:\nmodel = RandomForestClassifier(\n    n_estimators=300,\n    max_depth=6,\n    min_samples_split=4,\n    min_samples_leaf=2,\n    random_state=42\n)\nmodel.fit(X, y)\n# We Make predictions:\npredictions = model.predict(X_test)\n\n# We Create submission file\nsubmission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Model trained and submission.csv is ready!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T18:05:55.807059Z","iopub.execute_input":"2026-02-09T18:05:55.807451Z","iopub.status.idle":"2026-02-09T18:05:56.402505Z","shell.execute_reply.started":"2026-02-09T18:05:55.807417Z","shell.execute_reply":"2026-02-09T18:05:56.401107Z"}},"outputs":[{"name":"stdout","text":"Model trained and submission.csv is ready!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nsubmission.to_csv('submission_v1.csv', index=False)\nprint(\"Model trained and submission_v1.csv is ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T18:07:02.115165Z","iopub.execute_input":"2026-02-09T18:07:02.115532Z","iopub.status.idle":"2026-02-09T18:07:02.123630Z","shell.execute_reply.started":"2026-02-09T18:07:02.115507Z","shell.execute_reply":"2026-02-09T18:07:02.122473Z"}},"outputs":[{"name":"stdout","text":"Model trained and submission_v1.csv is ready!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\n\n# List all files in the working directory\nos.listdir(\"/kaggle/working\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T19:16:51.916576Z","iopub.execute_input":"2026-02-08T19:16:51.916943Z","iopub.status.idle":"2026-02-08T19:16:51.923129Z","shell.execute_reply.started":"2026-02-08T19:16:51.916913Z","shell.execute_reply":"2026-02-08T19:16:51.922075Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"['.virtual_documents', 'submission.csv']"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Create a clickable link to download submission.csv\nFileLink(\"/kaggle/working/submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T19:18:13.622894Z","iopub.execute_input":"2026-02-08T19:18:13.623560Z","iopub.status.idle":"2026-02-08T19:18:13.629596Z","shell.execute_reply.started":"2026-02-08T19:18:13.623528Z","shell.execute_reply":"2026-02-08T19:18:13.628693Z"},"jupyter":{"source_hidden":true}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='/kaggle/working/submission.csv' target='_blank'>/kaggle/working/submission.csv</a><br>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"!ls\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T19:28:08.708115Z","iopub.execute_input":"2026-02-08T19:28:08.708463Z","iopub.status.idle":"2026-02-08T19:28:08.841780Z","shell.execute_reply.started":"2026-02-08T19:28:08.708430Z","shell.execute_reply":"2026-02-08T19:28:08.840611Z"}},"outputs":[{"name":"stdout","text":"submission.csv\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!ls /kaggle/working/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T19:28:26.557870Z","iopub.execute_input":"2026-02-08T19:28:26.558314Z","iopub.status.idle":"2026-02-08T19:28:26.684726Z","shell.execute_reply.started":"2026-02-08T19:28:26.558274Z","shell.execute_reply":"2026-02-08T19:28:26.683581Z"}},"outputs":[{"name":"stdout","text":"submission.csv\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import pandas as pd\n\n# Load your submission file\ndf = pd.read_csv(\"submission.csv\")\n\n# See the first few rows\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-08T19:34:53.997066Z","iopub.execute_input":"2026-02-08T19:34:53.998126Z","iopub.status.idle":"2026-02-08T19:34:54.009327Z","shell.execute_reply.started":"2026-02-08T19:34:53.998081Z","shell.execute_reply":"2026-02-08T19:34:54.008056Z"}},"outputs":[{"name":"stdout","text":"   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         1\n","output_type":"stream"}],"execution_count":36}]}